{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from det3d.models.centerpoint import CenterPoint\n",
    "from det3d.types.pointcloud import PointCloud\n",
    "from det3d.utils import move_to_gpu, move_to_cpu, print_dict_tensors_size\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 定义一个Toy Dataset（与模型输出保持一致）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(batch_data):\n",
    "    \"\"\"\n",
    "    batch_data: list of samples, 每个样本格式为 (pc, label)\n",
    "        其中 pc 为一个对象，其属性 points 为 numpy array (N_i, feature_dim)\n",
    "        label 为该帧对应的标签数据（例如 gt dict 等）。\n",
    "    \n",
    "    返回：\n",
    "        padded_points: shape [batch_size, max_num_points, feature_dim+1]\n",
    "           —— 第一列为 batch_index, 后面的列为原始特征\n",
    "        labels: 列表形式保存每个样本的 label\n",
    "        lengths: 每帧原始点数，方便后续做 mask\n",
    "    \"\"\"\n",
    "    point_clouds = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    # 遍历每个样本，同时记录下样本在 batch 中的 index\n",
    "    for batch_idx, sample in enumerate(batch_data):\n",
    "        # sample[0].points 是一个 numpy array，形状为 (N_i, feature_dim)\n",
    "        points_tensor = torch.tensor(sample[0].points, dtype=torch.float)\n",
    "        lengths.append(points_tensor.shape[0])\n",
    "        labels.append(sample[1])\n",
    "        # 为当前样本所有的点创建 batch index 列\n",
    "        batch_idx_tensor = torch.full((points_tensor.size(0), 1), batch_idx, dtype=torch.float)\n",
    "        # 拼接，得到新的 tensor，形状为 (N_i, feature_dim + 1)\n",
    "        points_tensor = torch.cat([batch_idx_tensor, points_tensor], dim=1)\n",
    "        point_clouds.append(points_tensor)\n",
    "    \n",
    "    # 使用 pad_sequence 对齐所有点云，padding_value=0\n",
    "    padded_points = pad_sequence(point_clouds, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return padded_points, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        voxel_size: list,          # [voxel_x, voxel_y, voxel_z] (这里只使用 x, y)\n",
    "        feature_map_stride: int,\n",
    "        num_classes: int,\n",
    "        pc_range: list,\n",
    "        debug: bool = False        # 调试模式，默认 False\n",
    "    ):\n",
    "        self.num_samples = 100\n",
    "        self.num_points = 1000\n",
    "        self.voxel_size = voxel_size\n",
    "        self.feature_map_stride = feature_map_stride\n",
    "        self.num_classes = num_classes\n",
    "        self.debug = debug\n",
    "\n",
    "        self.label_mapping = {\n",
    "            \"Car\": 0,\n",
    "            \"Cyclist\": 1,\n",
    "            \"Pedestrian\": 2,\n",
    "            # \"Hero\": 3\n",
    "        }\n",
    "\n",
    "        # ------------------------------\n",
    "        # 读取本地点云数据\n",
    "        # ------------------------------\n",
    "        pc_path = '/workspace/rosbags/archive/data_city/data_city/lidar_livox'\n",
    "        npy_files = glob.glob(f\"{pc_path}/*.npy\")\n",
    "        self.pc_list = [np.load(file) for file in npy_files]\n",
    "\n",
    "        # 使用预设的 pc_range\n",
    "        self.point_cloud_range = pc_range\n",
    "        if self.debug:\n",
    "            print(f'[DEBUG] Computed point_cloud_range: {self.point_cloud_range}')\n",
    "\n",
    "        # ------------------------------\n",
    "        # 读取本地标签数据\n",
    "        # ------------------------------\n",
    "        label_path = '/workspace/rosbags/archive/data_city/data_city/label3'\n",
    "        labels = glob.glob(f\"{label_path}/*.txt\")\n",
    "        label_list = []\n",
    "        for label_file in labels:\n",
    "            gt_dict = dict(\n",
    "                gt_boxes = [],\n",
    "                gt_labels = [],\n",
    "            )\n",
    "            with open(label_file, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    raw_line_list = line.split(\" \")\n",
    "                    # 前7个数字对应 [x, y, z, l, w, h, rot]\n",
    "                    xyzlwhr = torch.Tensor([float(x) for x in raw_line_list[:-1]])\n",
    "                    cur_label = raw_line_list[-1].replace('\\n','').strip()\n",
    "                    if cur_label == \"Hero\":\n",
    "                        continue\n",
    "                    gt_dict[\"gt_boxes\"].append(xyzlwhr)\n",
    "                    gt_dict[\"gt_labels\"].append(self.label_mapping[cur_label])\n",
    "            if len(gt_dict[\"gt_boxes\"]) > 0:\n",
    "                gt_dict[\"gt_boxes\"] = torch.stack(gt_dict[\"gt_boxes\"])\n",
    "                gt_dict[\"gt_labels\"] = torch.tensor(gt_dict[\"gt_labels\"], dtype=torch.long)\n",
    "            else:\n",
    "                gt_dict[\"gt_boxes\"] = torch.empty((0, 7))\n",
    "                gt_dict[\"gt_labels\"] = torch.empty((0,), dtype=torch.long)\n",
    "            label_list.append(gt_dict)\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    # ---------- 辅助函数 ----------\n",
    "\n",
    "    def get_bev_size(self):\n",
    "        \"\"\"\n",
    "        根据 point_cloud_range 和 voxel_size 计算 BEV 特征图尺寸 (H, W)。\n",
    "        \"\"\"\n",
    "        x_min, y_min, z_min, x_max, y_max, z_max = self.point_cloud_range\n",
    "        vx, vy = self.voxel_size[0], self.voxel_size[1]\n",
    "        stride = self.feature_map_stride\n",
    "        W = round((x_max - x_min) / (vx * stride))\n",
    "        H = round((y_max - y_min) / (vy * stride))\n",
    "        return H, W\n",
    "\n",
    "    def map_to_bev(self, x, y):\n",
    "        \"\"\"\n",
    "        将 (x, y) 坐标映射到 BEV 特征图中，返回：\n",
    "         - bev_x, bev_y: 浮点数坐标（未取整）\n",
    "         - x_int, y_int: 转换为整数索引（grid cell 坐标）\n",
    "        \"\"\"\n",
    "        x_min, y_min, _, _, _, _ = self.point_cloud_range\n",
    "        vx, vy = self.voxel_size[0], self.voxel_size[1]\n",
    "        stride = self.feature_map_stride\n",
    "        bev_x = (x - x_min) / (vx * stride)\n",
    "        bev_y = (y - y_min) / (vy * stride)\n",
    "        x_int, y_int = int(bev_x), int(bev_y)\n",
    "        return bev_x, bev_y, x_int, y_int\n",
    "\n",
    "    def get_gaussian_patch_indices(self, center_idx, radius, H, W):\n",
    "        \"\"\"\n",
    "        根据中心索引 center_idx = (x_int, y_int) 和高斯核半径 radius，\n",
    "        计算 BEV 区域及高斯核 patch 的索引范围：\n",
    "            h_x_min, h_x_max, h_y_min, h_y_max,\n",
    "            g_x_min, g_x_max, g_y_min, g_y_max\n",
    "        \"\"\"\n",
    "        x_int, y_int = center_idx\n",
    "        left = x_int - radius\n",
    "        right = x_int + radius + 1\n",
    "        top = y_int - radius\n",
    "        bottom = y_int + radius + 1\n",
    "\n",
    "        g_x_min = max(0, -left)\n",
    "        g_x_max = (2 * radius + 1) - max(0, right - W)\n",
    "        g_y_min = max(0, -top)\n",
    "        g_y_max = (2 * radius + 1) - max(0, bottom - H)\n",
    "\n",
    "        h_x_min = max(0, left)\n",
    "        h_x_max = min(W, right)\n",
    "        h_y_min = max(0, top)\n",
    "        h_y_max = min(H, bottom)\n",
    "\n",
    "        return h_x_min, h_x_max, h_y_min, h_y_max, g_x_min, g_x_max, g_y_min, g_y_max\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. 加载点云和对应 GT 标签字典\n",
    "        pc = PointCloud(self.pc_list[idx])\n",
    "        gt_dict = self.label_list[idx]\n",
    "\n",
    "        # 对 GT 进行过滤：只保留在 BEV 内的 box\n",
    "        original_boxes = gt_dict['gt_boxes']\n",
    "        original_labels = gt_dict['gt_labels']\n",
    "        H, W = self.get_bev_size()\n",
    "\n",
    "        valid_reg_list = []\n",
    "        valid_ind_list = []\n",
    "        valid_size_list = []\n",
    "        valid_boxes_list = []\n",
    "        valid_labels_list = []\n",
    "        valid_height_list = []\n",
    "        valid_rot_list = []\n",
    "\n",
    "        for i, box in enumerate(original_boxes):\n",
    "            x, y, z_val, l_box, w_box, h_box, rot_val = box.tolist()\n",
    "            bev_x, bev_y, x_int, y_int = self.map_to_bev(x, y)\n",
    "            # 只保留投影落在 [0,W) 和 [0,H) 内的 box\n",
    "            if 0 <= x_int < W and 0 <= y_int < H:\n",
    "                valid_boxes_list.append(box)\n",
    "                valid_labels_list.append(original_labels[i])\n",
    "                offset = [bev_x - x_int, bev_y - y_int]\n",
    "                valid_reg_list.append(offset)\n",
    "                valid_ind_list.append(y_int * W + x_int)\n",
    "                size_w = l_box / (self.voxel_size[0] * self.feature_map_stride)\n",
    "                size_h = w_box / (self.voxel_size[1] * self.feature_map_stride)\n",
    "                valid_size_list.append([size_w, size_h])\n",
    "                valid_height_list.append(z_val)\n",
    "                valid_rot_list.append(rot_val)\n",
    "            else:\n",
    "                if self.debug:\n",
    "                    print(f'[DEBUG] Box {i} with center ({x:.2f},{y:.2f}) mapped to ({x_int},{y_int}) is out of BEV range.')\n",
    "\n",
    "        if len(valid_boxes_list) > 0:\n",
    "            filtered_gt_boxes = torch.stack(valid_boxes_list)\n",
    "            filtered_gt_labels = torch.tensor(valid_labels_list, dtype=torch.long)\n",
    "            reg = torch.tensor(valid_reg_list, dtype=torch.float32)      # [valid_num, 2]\n",
    "            ind = torch.tensor(valid_ind_list, dtype=torch.long)           # [valid_num]\n",
    "            size = torch.tensor(valid_size_list, dtype=torch.float32)      # [valid_num, 2]\n",
    "            reg_mask = torch.ones(len(valid_ind_list), dtype=torch.uint8)  # 有效标记\n",
    "            height = torch.tensor(valid_height_list, dtype=torch.float32)  # [valid_num]\n",
    "            rot = torch.tensor(valid_rot_list, dtype=torch.float32)        # [valid_num]\n",
    "        else:\n",
    "            filtered_gt_boxes = torch.empty((0, 7))\n",
    "            filtered_gt_labels = torch.empty((0,), dtype=torch.long)\n",
    "            reg = torch.empty((0, 2), dtype=torch.float32)\n",
    "            ind = torch.empty((0,), dtype=torch.long)\n",
    "            size = torch.empty((0, 2), dtype=torch.float32)\n",
    "            reg_mask = torch.empty((0,), dtype=torch.uint8)\n",
    "            height = torch.empty((0,), dtype=torch.float32)\n",
    "            rot = torch.empty((0,), dtype=torch.float32)\n",
    "\n",
    "        # 生成 GT 热力图（仅用有效的 box）\n",
    "        filtered_heatmap = self.generate_heatmap(\n",
    "            filtered_gt_boxes, filtered_gt_labels,\n",
    "            point_cloud_range=self.point_cloud_range,\n",
    "            voxel_size=self.voxel_size,\n",
    "            feature_map_stride=self.feature_map_stride,\n",
    "            num_classes=self.num_classes\n",
    "        )\n",
    "\n",
    "        # 构造返回的 GT 字典\n",
    "        final_gt = {\n",
    "            'gt_boxes': filtered_gt_boxes,   # 只包含有效 box\n",
    "            'gt_labels': filtered_gt_labels,\n",
    "            'heatmap': filtered_heatmap,\n",
    "            'ind': ind,\n",
    "            'reg': reg,\n",
    "            'reg_mask': reg_mask,\n",
    "            'size': size,\n",
    "            'height': height,\n",
    "            'rot': rot\n",
    "        }\n",
    "        \n",
    "        return pc, final_gt\n",
    "\n",
    "    def gaussian2D(self, shape, sigma=1):\n",
    "        \"\"\"生成 2D 高斯核矩阵\"\"\"\n",
    "        m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "        y, x = np.ogrid[-m:m+1, -n:n+1]\n",
    "        h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "        h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "        return h\n",
    "\n",
    "    def gaussian_radius(self, det_size, min_overlap=0.5):\n",
    "        \"\"\"计算高斯核半径（基于目标尺寸）\"\"\"\n",
    "        height, width = det_size\n",
    "        a1 = 1\n",
    "        b1 = (height + width)\n",
    "        c1 = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "        sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "        r1 = (b1 - sq1) / (2 * a1)\n",
    "        \n",
    "        a2 = 4\n",
    "        b2 = 2 * (height + width)\n",
    "        c2 = (1 - min_overlap) * width * height\n",
    "        sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "        r2 = (b2 - sq2) / (2 * a2)\n",
    "        \n",
    "        a3 = 4 * min_overlap\n",
    "        b3 = -2 * min_overlap * (height + width)\n",
    "        c3 = (min_overlap - 1) * width * height\n",
    "        sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "        r3 = (b3 + sq3) / (2 * a3)\n",
    "        \n",
    "        return min(r1, r2, r3)\n",
    "\n",
    "    def generate_heatmap(self, gt_boxes, gt_labels, point_cloud_range, voxel_size,\n",
    "                         feature_map_stride=4, num_classes=3):\n",
    "        \"\"\"\n",
    "        根据 gt_boxes 和 gt_labels 生成形状为 [num_classes, H, W] 的 heatmap，\n",
    "        H,W 与 get_bev_size() 计算一致。\n",
    "        \"\"\"\n",
    "        dx, dy = voxel_size[0], voxel_size[1]\n",
    "        H, W = self.get_bev_size()\n",
    "        if self.debug:\n",
    "            print(f'[DEBUG] BEV feature map size: H={H}, W={W}')\n",
    "\n",
    "        heatmap = torch.zeros((num_classes, H, W))\n",
    "        for i, (box, label) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "            x, y, _, dx_size, dy_size, _, _ = box.tolist()\n",
    "            bev_x, bev_y, x_int, y_int = self.map_to_bev(x, y)\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: center=({x:.2f}, {y:.2f}), mapped BEV=({bev_x:.2f}, {bev_y:.2f}) -> (x_int, y_int)=({x_int}, {y_int}), label={label}')\n",
    "            if not (0 <= x_int < W and 0 <= y_int < H):\n",
    "                if self.debug:\n",
    "                    print(f'[DEBUG] Box {i} is out of BEV bounds, skipped.')\n",
    "                continue\n",
    "            # 计算 box 在 BEV 上的尺寸（顺序与 voxel_size 保持一致）\n",
    "            box_hw = (dy_size / dy / feature_map_stride, dx_size / dx / feature_map_stride)\n",
    "            radius = self.gaussian_radius(box_hw)\n",
    "            radius = max(0, int(radius))\n",
    "            diameter = 2 * radius + 1\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: box_hw={box_hw}, gaussian radius={radius}, diameter={diameter}')\n",
    "            \n",
    "            gaussian = self.gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "            gaussian = torch.from_numpy(gaussian).float()\n",
    "            \n",
    "            h_x_min, h_x_max, h_y_min, h_y_max, g_x_min, g_x_max, g_y_min, g_y_max = \\\n",
    "                self.get_gaussian_patch_indices((x_int, y_int), radius, H, W)\n",
    "            \n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: BEV region: x[{h_x_min}:{h_x_max}], y[{h_y_min}:{h_y_max}]')\n",
    "                print(f'[DEBUG] Box {i}: Gaussian patch indices: x[{g_x_min}:{g_x_max}], y[{g_y_min}:{g_y_max}]')\n",
    "            \n",
    "            masked_heatmap = heatmap[label, h_y_min:h_y_max, h_x_min:h_x_max]\n",
    "            masked_gaussian = gaussian[g_y_min:g_y_max, g_x_min:g_x_max]\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: before update, heatmap sum={masked_heatmap.sum():.4f}, gaussian sum={masked_gaussian.sum():.4f}')\n",
    "            if masked_gaussian.shape != masked_heatmap.shape:\n",
    "                if self.debug:\n",
    "                    print(f'[DEBUG] Box {i}: Shape mismatch: heatmap patch shape {masked_heatmap.shape}, gaussian patch shape {masked_gaussian.shape}. Skipping this box.')\n",
    "                continue\n",
    "            heatmap[label, h_y_min:h_y_max, h_x_min:h_x_max] = torch.maximum(masked_heatmap, masked_gaussian)\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: after update, new heatmap channel {label} sum={heatmap[label].sum():.4f}')\n",
    "        \n",
    "        if self.debug:\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig, axs = plt.subplots(1, num_classes, figsize=(5 * num_classes, 4))\n",
    "            if num_classes == 1:\n",
    "                axs = [axs]\n",
    "            for i in range(num_classes):\n",
    "                heat = heatmap[i].numpy()\n",
    "                im = axs[i].imshow(heat, cmap='hot', interpolation='nearest')\n",
    "                axs[i].set_title(f\"Heatmap for class {i}\")\n",
    "                fig.colorbar(im, ax=axs[i])\n",
    "            plt.suptitle(\"All Channel Heatmaps\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到dataset中每个data的input为一帧点云 (N,4), gt为boxes,labels,scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 定义一个简单的Toy模型，使用提供的CenterPointModel作为输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CenterPoint([0.2,0.2,0.2],[0.2,0.2,0.2,0.2,0.2,0.2])\n",
    "# summary(model,input_size=(2,10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些尺寸实际上正是由各个预测分支的设计决定的。一般来说，CenterPoint 和类似模型会为每个任务分配固定数量的输出通道，然后对整个 BEV 特征图进行卷积预测。具体解释如下：\n",
    "\n",
    "1. **raw_hm (热力图)**  \n",
    "   - 输出尺寸为 `[3, 448, 1120]`，其中 3 表示预测类别数（这里类别数为 3，比如 Vehicle、Pedestrian、Cyclist）。因此，每个类别对应一个通道，最终形成一个形状为 `[num_classes, H, W]` 的热力图。\n",
    "\n",
    "2. **raw_center (中心偏移)**  \n",
    "   - 输出尺寸为 `[2, 448, 1120]`，这里 2 通常表示在 BEV 特征图上，每个 grid cell 内的预测中心坐标（x 和 y 的残差）。即从离散的网格中心到真实中心的偏移。\n",
    "\n",
    "3. **raw_center_z (高度/中心z值)**  \n",
    "   - 输出尺寸为 `[1, 448, 1120]`，只有 1 个通道，用于预测目标在 z 轴方向上的位置（或者说目标的高度信息）。\n",
    "\n",
    "4. **raw_dim (尺寸)**  \n",
    "   - 输出尺寸为 `[3, 448, 1120]`，这里 3 个通道分别对应目标的长、宽、高（l, w, h）的预测值，通常预测的是对数尺度（后续可能会做 exp 处理）或者直接在 BEV 中的尺寸。\n",
    "\n",
    "5. **raw_rot (旋转角度)**  \n",
    "   - 输出尺寸为 `[2, 448, 1120]`，通常用两个通道分别表示旋转角度的 sin 和 cos 值，这样可以避免角度回归带来的周期性问题。\n",
    "\n",
    "**总结：**  \n",
    "- 每个分支的通道数即对应任务的输出数量。  \n",
    "- 448 和 1120 是 BEV 特征图的高度和宽度（由点云范围、voxel 大小和下采样系数决定）。  \n",
    "- 例如，hm 分支输出 3 个通道对应 3 个类别，中心偏移输出 2 个通道（x,y），中心高度（z）输出 1 个通道，尺寸输出 3 个通道，而旋转输出 2 个通道。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(pred, gt, alpha=2, beta=4):\n",
    "    \"\"\"\n",
    "    实现一个简单版本的 focal loss，\n",
    "    输入 pred 和 gt 均为 [num_classes, H, W] 的张量\n",
    "    pred 应该是经过 sigmoid 激活后的预测热力图\n",
    "    \"\"\"\n",
    "    assert(isinstance(pred,torch.Tensor))\n",
    "    assert(isinstance(gt, torch.Tensor))\n",
    "    \n",
    "    pos_inds = (gt == 1).float()\n",
    "    neg_inds = (gt < 1).float()\n",
    "\n",
    "    pos_loss = -torch.log(pred + 1e-4) * torch.pow(1 - pred, alpha) * pos_inds\n",
    "    neg_loss = -torch.log(1 - pred + 1e-4) * torch.pow(pred, alpha) * torch.pow(1 - gt, beta) * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.sum()\n",
    "    if num_pos == 0:\n",
    "        loss = neg_loss.sum()\n",
    "    else:\n",
    "        loss = (pos_loss.sum() + neg_loss.sum()) / num_pos\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_loss(pred_dicts, gt_dicts):\n",
    "    total_offset_loss = 0.0\n",
    "    total_height_loss = 0.0\n",
    "    batch_count = len(pred_dicts)\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        pred = pred_dicts[i]\n",
    "        gt = gt_dicts[i]\n",
    "        \n",
    "        raw_center = pred[\"raw_center\"]   # shape: [2, H, W]\n",
    "        _, H, W = raw_center.shape\n",
    "        raw_center_flat = raw_center.view(2, -1).transpose(0, 1)  # shape: [H*W, 2]\n",
    "        \n",
    "        raw_center_z = pred[\"raw_center_z\"]  # shape: [1, H, W]\n",
    "        raw_center_z_flat = raw_center_z.view(1, -1).transpose(0, 1)  # shape: [H*W, 1]\n",
    "        \n",
    "        # 确保索引为 long 类型\n",
    "        indices = gt[\"ind\"].to(torch.long)\n",
    "        if indices.nelement() > 0:\n",
    "            pred_offset = raw_center_flat[indices]  # shape: [N, 2]\n",
    "            pred_height = raw_center_z_flat[indices]  # shape: [N, 1]\n",
    "            \n",
    "            gt_offset = gt[\"reg\"]                 # shape: [N, 2]\n",
    "            gt_height = gt[\"height\"].unsqueeze(-1)  # shape: [N, 1]\n",
    "            reg_mask = gt[\"reg_mask\"].float()\n",
    "            num_valid = reg_mask.sum() + 1e-4\n",
    "\n",
    "            offset_loss = F.l1_loss(pred_offset, gt_offset, reduction=\"sum\") / num_valid\n",
    "            height_loss = F.l1_loss(pred_height, gt_height, reduction=\"sum\") / num_valid\n",
    "        else:\n",
    "            # 如果没有有效目标，则构造一个与预测相关联的零 loss 以便 backward 正常\n",
    "            offset_loss = raw_center_flat[0].sum() * 0.0\n",
    "            height_loss = raw_center_z_flat[0].sum() * 0.0\n",
    "        \n",
    "        total_offset_loss += offset_loss\n",
    "        total_height_loss += height_loss\n",
    "\n",
    "    avg_offset_loss = total_offset_loss / batch_count\n",
    "    avg_height_loss = total_height_loss / batch_count\n",
    "\n",
    "    return avg_offset_loss, avg_height_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred_dicts, gt_dicts):\n",
    "    \"\"\"\n",
    "    计算每个 batch（pred_dicts[i] 和 gt_dicts[i] 对应一批）的 focal loss，\n",
    "    然后求平均总损失。\n",
    "\n",
    "    输入：\n",
    "      pred_dicts: list，每个元素为一个 batch 的预测 dict，\n",
    "                   其中包含键 'raw_hm'，形状为 [num_classes, H, W]\n",
    "      gt_dicts:   list，每个元素为一个 batch 的 GT dict，\n",
    "                   其中包含键 'heatmap'，形状为 [num_classes, H, W]\n",
    "\n",
    "    返回：\n",
    "      平均 focal loss（标量 tensor）\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    batch_count = len(pred_dicts)\n",
    "    for i in range(batch_count):\n",
    "        # print(f\"计算第{i+1}个batch的 focal loss ...\")\n",
    "        # 获取该 batch 的预测热力图，注意需要先经过 sigmoid\n",
    "        # pred_hm = torch.sigmoid(pred_dicts[i][\"raw_hm\"])  # [num_classes, H, W]\n",
    "        # gt_hm = gt_dicts[i][\"heatmap\"]                    # [num_classes, H, W]\n",
    "\n",
    "        # fc_loss = focal_loss(pred_hm, gt_hm)\n",
    "        # total_loss += fc_loss\n",
    "        \n",
    "        xy_loss,z_loss = regression_loss(pred_dicts,gt_dicts)\n",
    "        total_loss += xy_loss + z_loss\n",
    "\n",
    "    avg_loss = total_loss / batch_count\n",
    "    # print(\"平均 focal loss:\", avg_loss.item())\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = [0.2, 0.2, 0.2]\n",
    "feature_map_stride = 1\n",
    "num_classes = 3\n",
    "batch_size = 1\n",
    "pc_range = [0, -44.8, -2, 224, 44.8, 4]\n",
    "\n",
    "dataset = PointCloudDataset(debug=False,\n",
    "                            voxel_size=voxel_size,\n",
    "                            feature_map_stride=feature_map_stride,\n",
    "                            pc_range=pc_range,\n",
    "                            num_classes=num_classes)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=False,collate_fn=myfunc,drop_last=True)\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False,collate_fn=myfunc,drop_last=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 这行注释掉\n",
    "\n",
    "model = CenterPoint(\n",
    "    voxel_size=voxel_size,\n",
    "    pc_range=pc_range,\n",
    "    feature_map_stride=feature_map_stride,\n",
    "    ).to(device)\n",
    "\n",
    "torch.cuda.empty_cache()  \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1]['gt_boxes'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in trainloader:\n",
    "#     pc_, gt_,len_ = i\n",
    "#     print(type(pc_))\n",
    "#     print(type(gt_))\n",
    "#     print(pc_.size())\n",
    "#     print(pc_[:,:3,:].size())\n",
    "#     print(len(gt_))\n",
    "#     pprint(gt_[0])\n",
    "#     print(type(gt_[0]['gt_boxes']))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 训练模式\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (pointclouds, gt_dicts, lengths) in enumerate(trainloader):\n",
    "        # 将点云数据和对应的标签移到 CPU 上（如果不调用 .cuda() 则本来就在 CPU）\n",
    "        pointclouds = move_to_gpu(pointclouds)\n",
    "        gt_dicts = move_to_gpu(gt_dicts)\n",
    "        \n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        pred_dicts = model(pointclouds)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = compute_loss(pred_dicts, gt_dicts)\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / (i + 1):.4f}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {running_loss / len(trainloader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

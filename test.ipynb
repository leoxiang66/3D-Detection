{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from det3d.models.centerpoint import CenterPoint\n",
    "from det3d.types.pointcloud import PointCloud\n",
    "from det3d.utils import move_to_gpu, move_to_cpu, print_dict_tensors_size\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 定义 Dataset（与模型输出保持一致）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(batch_data):\n",
    "    \"\"\"\n",
    "    batch_data: list of samples, 每个样本格式为 (pc, label)\n",
    "        其中 pc 为一个对象，其属性 points 为 numpy array (N_i, feature_dim)\n",
    "        label 为该帧对应的标签数据（例如 gt dict 等）。\n",
    "    \n",
    "    返回：\n",
    "        padded_points: shape [batch_size, max_num_points, feature_dim+1]\n",
    "           —— 第一列为 batch_index, 后面的列为原始特征\n",
    "        labels: 列表形式保存每个样本的 label\n",
    "        lengths: 每帧原始点数，方便后续做 mask\n",
    "    \"\"\"\n",
    "    point_clouds = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    # 遍历每个样本，同时记录下样本在 batch 中的 index\n",
    "    for batch_idx, sample in enumerate(batch_data):\n",
    "        # sample[0].points 是一个 numpy array，形状为 (N_i, feature_dim)\n",
    "        points_tensor = torch.tensor(sample[0].points, dtype=torch.float)\n",
    "        lengths.append(points_tensor.shape[0])\n",
    "        labels.append(sample[1])\n",
    "        # 为当前样本所有的点创建 batch index 列\n",
    "        batch_idx_tensor = torch.full((points_tensor.size(0), 1), batch_idx, dtype=torch.float)\n",
    "        # 拼接，得到新的 tensor，形状为 (N_i, feature_dim + 1)\n",
    "        points_tensor = torch.cat([batch_idx_tensor, points_tensor], dim=1)\n",
    "        point_clouds.append(points_tensor)\n",
    "    \n",
    "    # 使用 pad_sequence 对齐所有点云，padding_value=0\n",
    "    padded_points = pad_sequence(point_clouds, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return padded_points, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        voxel_size: list,          # [voxel_x, voxel_y, voxel_z] (这里只使用 x, y)\n",
    "        feature_map_stride: int,\n",
    "        num_classes: int,\n",
    "        pc_range: list,\n",
    "        debug: bool = False        # 调试模式，默认 False\n",
    "    ):\n",
    "        self.num_samples = 100\n",
    "        self.num_points = 1000\n",
    "        self.voxel_size = voxel_size\n",
    "        self.feature_map_stride = feature_map_stride\n",
    "        self.num_classes = num_classes\n",
    "        self.debug = debug\n",
    "\n",
    "        self.label_mapping = {\n",
    "            \"Car\": 0,\n",
    "            \"Cyclist\": 1,\n",
    "            \"Pedestrian\": 2,\n",
    "            # \"Hero\": 3\n",
    "        }\n",
    "\n",
    "        # ------------------------------\n",
    "        # 读取本地点云数据\n",
    "        # ------------------------------\n",
    "        pc_path = '/workspace/rosbags/archive/data_city/data_city/lidar_livox'\n",
    "        npy_files = glob.glob(f\"{pc_path}/*.npy\")\n",
    "        self.pc_list = [np.load(file) for file in npy_files]\n",
    "\n",
    "        # 使用预设的 pc_range\n",
    "        self.point_cloud_range = pc_range\n",
    "        if self.debug:\n",
    "            print(f'[DEBUG] Computed point_cloud_range: {self.point_cloud_range}')\n",
    "\n",
    "        # ------------------------------\n",
    "        # 读取本地标签数据\n",
    "        # ------------------------------\n",
    "        label_path = '/workspace/rosbags/archive/data_city/data_city/label3'\n",
    "        labels = glob.glob(f\"{label_path}/*.txt\")\n",
    "        label_list = []\n",
    "        for label_file in labels:\n",
    "            gt_dict = dict(\n",
    "                gt_boxes = [],\n",
    "                gt_labels = [],\n",
    "            )\n",
    "            with open(label_file, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    raw_line_list = line.split(\" \")\n",
    "                    # 前7个数字对应 [x, y, z, l, w, h, rot]\n",
    "                    xyzlwhr = torch.Tensor([float(x) for x in raw_line_list[:-1]])\n",
    "                    cur_label = raw_line_list[-1].replace('\\n','').strip()\n",
    "                    if cur_label == \"Hero\":\n",
    "                        continue\n",
    "                    gt_dict[\"gt_boxes\"].append(xyzlwhr)\n",
    "                    gt_dict[\"gt_labels\"].append(self.label_mapping[cur_label])\n",
    "            if len(gt_dict[\"gt_boxes\"]) > 0:\n",
    "                gt_dict[\"gt_boxes\"] = torch.stack(gt_dict[\"gt_boxes\"])\n",
    "                gt_dict[\"gt_labels\"] = torch.tensor(gt_dict[\"gt_labels\"], dtype=torch.long)\n",
    "            else:\n",
    "                gt_dict[\"gt_boxes\"] = torch.empty((0, 7))\n",
    "                gt_dict[\"gt_labels\"] = torch.empty((0,), dtype=torch.long)\n",
    "            label_list.append(gt_dict)\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    # ---------- 辅助函数 ----------\n",
    "\n",
    "    def get_bev_size(self):\n",
    "        \"\"\"\n",
    "        根据 point_cloud_range 和 voxel_size 计算 BEV 特征图尺寸 (H, W)。\n",
    "        \"\"\"\n",
    "        x_min, y_min, z_min, x_max, y_max, z_max = self.point_cloud_range\n",
    "        vx, vy = self.voxel_size[0], self.voxel_size[1]\n",
    "        stride = self.feature_map_stride\n",
    "        W = round((x_max - x_min) / (vx * stride))\n",
    "        H = round((y_max - y_min) / (vy * stride))\n",
    "        return H, W\n",
    "\n",
    "    def map_to_bev(self, x, y):\n",
    "        \"\"\"\n",
    "        将 (x, y) 坐标映射到 BEV 特征图中，返回：\n",
    "         - bev_x, bev_y: 浮点数坐标（未取整）\n",
    "         - x_int, y_int: 转换为整数索引（grid cell 坐标）\n",
    "        \"\"\"\n",
    "        x_min, y_min, _, _, _, _ = self.point_cloud_range\n",
    "        vx, vy = self.voxel_size[0], self.voxel_size[1]\n",
    "        stride = self.feature_map_stride\n",
    "        bev_x = (x - x_min) / (vx * stride)\n",
    "        bev_y = (y - y_min) / (vy * stride)\n",
    "        x_int, y_int = int(bev_x), int(bev_y)\n",
    "        return bev_x, bev_y, x_int, y_int\n",
    "\n",
    "    def get_gaussian_patch_indices(self, center_idx, radius, H, W):\n",
    "        \"\"\"\n",
    "        根据中心索引 center_idx = (x_int, y_int) 和高斯核半径 radius，\n",
    "        计算 BEV 区域及高斯核 patch 的索引范围：\n",
    "            h_x_min, h_x_max, h_y_min, h_y_max,\n",
    "            g_x_min, g_x_max, g_y_min, g_y_max\n",
    "        \"\"\"\n",
    "        x_int, y_int = center_idx\n",
    "        left = x_int - radius\n",
    "        right = x_int + radius + 1\n",
    "        top = y_int - radius\n",
    "        bottom = y_int + radius + 1\n",
    "\n",
    "        g_x_min = max(0, -left)\n",
    "        g_x_max = (2 * radius + 1) - max(0, right - W)\n",
    "        g_y_min = max(0, -top)\n",
    "        g_y_max = (2 * radius + 1) - max(0, bottom - H)\n",
    "\n",
    "        h_x_min = max(0, left)\n",
    "        h_x_max = min(W, right)\n",
    "        h_y_min = max(0, top)\n",
    "        h_y_max = min(H, bottom)\n",
    "\n",
    "        return h_x_min, h_x_max, h_y_min, h_y_max, g_x_min, g_x_max, g_y_min, g_y_max\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. 加载点云和对应 GT 标签字典\n",
    "        pc = PointCloud(self.pc_list[idx])\n",
    "        gt_dict = self.label_list[idx]\n",
    "\n",
    "        # 对 GT 进行过滤：只保留在 BEV 内的 box\n",
    "        original_boxes = gt_dict['gt_boxes']\n",
    "        original_labels = gt_dict['gt_labels']\n",
    "        H, W = self.get_bev_size()\n",
    "\n",
    "        valid_reg_list = []\n",
    "        valid_ind_list = []\n",
    "        valid_size_list = []\n",
    "        valid_boxes_list = []\n",
    "        valid_labels_list = []\n",
    "        valid_height_list = []\n",
    "        valid_rot_list = []\n",
    "\n",
    "        for i, box in enumerate(original_boxes):\n",
    "            x, y, z_val, l_box, w_box, h_box, rot_val = box.tolist()\n",
    "            bev_x, bev_y, x_int, y_int = self.map_to_bev(x, y)\n",
    "            # 只保留投影落在 [0,W) 和 [0,H) 内的 box\n",
    "            if 0 <= x_int < W and 0 <= y_int < H:\n",
    "                valid_boxes_list.append(box)\n",
    "                valid_labels_list.append(original_labels[i])\n",
    "                offset = [bev_x - x_int, bev_y - y_int]\n",
    "                valid_reg_list.append(offset)\n",
    "                valid_ind_list.append(y_int * W + x_int)\n",
    "                size_w = l_box / (self.voxel_size[0] * self.feature_map_stride)\n",
    "                size_h = w_box / (self.voxel_size[1] * self.feature_map_stride)\n",
    "                size_z = h_box / (self.voxel_size[2] * self.feature_map_stride)\n",
    "                valid_size_list.append([size_w, size_h,size_z])\n",
    "                valid_height_list.append(z_val)\n",
    "                valid_rot_list.append(rot_val)\n",
    "            else:\n",
    "                if self.debug:\n",
    "                    print(f'[DEBUG] Box {i} with center ({x:.2f},{y:.2f}) mapped to ({x_int},{y_int}) is out of BEV range.')\n",
    "\n",
    "        if len(valid_boxes_list) > 0:\n",
    "            filtered_gt_boxes = torch.stack(valid_boxes_list)\n",
    "            filtered_gt_labels = torch.tensor(valid_labels_list, dtype=torch.long)\n",
    "            reg = torch.tensor(valid_reg_list, dtype=torch.float32)      # [valid_num, 2]\n",
    "            ind = torch.tensor(valid_ind_list, dtype=torch.long)           # [valid_num]\n",
    "            size = torch.tensor(valid_size_list, dtype=torch.float32)      # [valid_num, 2]\n",
    "            reg_mask = torch.ones(len(valid_ind_list), dtype=torch.uint8)  # 有效标记\n",
    "            height = torch.tensor(valid_height_list, dtype=torch.float32)  # [valid_num]\n",
    "            rot = torch.tensor(valid_rot_list, dtype=torch.float32)        # [valid_num]\n",
    "        else:\n",
    "            filtered_gt_boxes = torch.empty((0, 7))\n",
    "            filtered_gt_labels = torch.empty((0,), dtype=torch.long)\n",
    "            reg = torch.empty((0, 2), dtype=torch.float32)\n",
    "            ind = torch.empty((0,), dtype=torch.long)\n",
    "            size = torch.empty((0, 3), dtype=torch.float32)\n",
    "            reg_mask = torch.empty((0,), dtype=torch.uint8)\n",
    "            height = torch.empty((0,), dtype=torch.float32)\n",
    "            rot = torch.empty((0,), dtype=torch.float32)\n",
    "\n",
    "        # 生成 GT 热力图（仅用有效的 box）\n",
    "        filtered_heatmap = self.generate_heatmap(\n",
    "            filtered_gt_boxes, filtered_gt_labels,\n",
    "            point_cloud_range=self.point_cloud_range,\n",
    "            voxel_size=self.voxel_size,\n",
    "            feature_map_stride=self.feature_map_stride,\n",
    "            num_classes=self.num_classes\n",
    "        )\n",
    "\n",
    "        # 构造返回的 GT 字典\n",
    "        final_gt = {\n",
    "            'gt_boxes': filtered_gt_boxes,   # 只包含有效 box\n",
    "            'gt_labels': filtered_gt_labels,\n",
    "            'heatmap': filtered_heatmap,\n",
    "            'ind': ind,\n",
    "            'reg': reg,\n",
    "            'reg_mask': reg_mask,\n",
    "            'size': size,\n",
    "            'height': height,\n",
    "            'rot': rot\n",
    "        }\n",
    "        \n",
    "        return pc, final_gt\n",
    "\n",
    "    def gaussian2D(self, shape, sigma=1):\n",
    "        \"\"\"生成 2D 高斯核矩阵\"\"\"\n",
    "        m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "        y, x = np.ogrid[-m:m+1, -n:n+1]\n",
    "        h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "        h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "        return h\n",
    "\n",
    "    def gaussian_radius(self, det_size, min_overlap=0.5):\n",
    "        \"\"\"计算高斯核半径（基于目标尺寸）\"\"\"\n",
    "        height, width = det_size\n",
    "        a1 = 1\n",
    "        b1 = (height + width)\n",
    "        c1 = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "        sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "        r1 = (b1 - sq1) / (2 * a1)\n",
    "        \n",
    "        a2 = 4\n",
    "        b2 = 2 * (height + width)\n",
    "        c2 = (1 - min_overlap) * width * height\n",
    "        sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "        r2 = (b2 - sq2) / (2 * a2)\n",
    "        \n",
    "        a3 = 4 * min_overlap\n",
    "        b3 = -2 * min_overlap * (height + width)\n",
    "        c3 = (min_overlap - 1) * width * height\n",
    "        sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "        r3 = (b3 + sq3) / (2 * a3)\n",
    "        \n",
    "        return min(r1, r2, r3)\n",
    "\n",
    "    def generate_heatmap(self, gt_boxes, gt_labels, point_cloud_range, voxel_size,\n",
    "                         feature_map_stride=4, num_classes=3):\n",
    "        \"\"\"\n",
    "        根据 gt_boxes 和 gt_labels 生成形状为 [num_classes, H, W] 的 heatmap，\n",
    "        H,W 与 get_bev_size() 计算一致。\n",
    "        \"\"\"\n",
    "        dx, dy = voxel_size[0], voxel_size[1]\n",
    "        H, W = self.get_bev_size()\n",
    "        if self.debug:\n",
    "            print(f'[DEBUG] BEV feature map size: H={H}, W={W}')\n",
    "\n",
    "        heatmap = torch.zeros((num_classes, H, W))\n",
    "        for i, (box, label) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "            x, y, _, dx_size, dy_size, _, _ = box.tolist()\n",
    "            bev_x, bev_y, x_int, y_int = self.map_to_bev(x, y)\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: center=({x:.2f}, {y:.2f}), mapped BEV=({bev_x:.2f}, {bev_y:.2f}) -> (x_int, y_int)=({x_int}, {y_int}), label={label}')\n",
    "            if not (0 <= x_int < W and 0 <= y_int < H):\n",
    "                if self.debug:\n",
    "                    print(f'[DEBUG] Box {i} is out of BEV bounds, skipped.')\n",
    "                continue\n",
    "            # 计算 box 在 BEV 上的尺寸（顺序与 voxel_size 保持一致）\n",
    "            box_hw = (dy_size / dy / feature_map_stride, dx_size / dx / feature_map_stride)\n",
    "            radius = self.gaussian_radius(box_hw)\n",
    "            radius = max(0, int(radius))\n",
    "            diameter = 2 * radius + 1\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: box_hw={box_hw}, gaussian radius={radius}, diameter={diameter}')\n",
    "            \n",
    "            gaussian = self.gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "            gaussian = torch.from_numpy(gaussian).float()\n",
    "            \n",
    "            h_x_min, h_x_max, h_y_min, h_y_max, g_x_min, g_x_max, g_y_min, g_y_max = \\\n",
    "                self.get_gaussian_patch_indices((x_int, y_int), radius, H, W)\n",
    "            \n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: BEV region: x[{h_x_min}:{h_x_max}], y[{h_y_min}:{h_y_max}]')\n",
    "                print(f'[DEBUG] Box {i}: Gaussian patch indices: x[{g_x_min}:{g_x_max}], y[{g_y_min}:{g_y_max}]')\n",
    "            \n",
    "            masked_heatmap = heatmap[label, h_y_min:h_y_max, h_x_min:h_x_max]\n",
    "            masked_gaussian = gaussian[g_y_min:g_y_max, g_x_min:g_x_max]\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: before update, heatmap sum={masked_heatmap.sum():.4f}, gaussian sum={masked_gaussian.sum():.4f}')\n",
    "            if masked_gaussian.shape != masked_heatmap.shape:\n",
    "                if self.debug:\n",
    "                    print(f'[DEBUG] Box {i}: Shape mismatch: heatmap patch shape {masked_heatmap.shape}, gaussian patch shape {masked_gaussian.shape}. Skipping this box.')\n",
    "                continue\n",
    "            heatmap[label, h_y_min:h_y_max, h_x_min:h_x_max] = torch.maximum(masked_heatmap, masked_gaussian)\n",
    "            if self.debug:\n",
    "                print(f'[DEBUG] Box {i}: after update, new heatmap channel {label} sum={heatmap[label].sum():.4f}')\n",
    "        \n",
    "        if self.debug:\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig, axs = plt.subplots(1, num_classes, figsize=(5 * num_classes, 4))\n",
    "            if num_classes == 1:\n",
    "                axs = [axs]\n",
    "            for i in range(num_classes):\n",
    "                heat = heatmap[i].numpy()\n",
    "                im = axs[i].imshow(heat, cmap='hot', interpolation='nearest')\n",
    "                axs[i].set_title(f\"Heatmap for class {i}\")\n",
    "                fig.colorbar(im, ax=axs[i])\n",
    "            plt.suptitle(\"All Channel Heatmaps\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到dataset中每个data的input为一帧点云 (N,4), gt为boxes,labels,scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 使用提供的CenterPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CenterPoint([0.2,0.2,0.2],[0.2,0.2,0.2,0.2,0.2,0.2])\n",
    "# summary(model,input_size=(2,10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些尺寸实际上正是由各个预测分支的设计决定的。一般来说，CenterPoint 和类似模型会为每个任务分配固定数量的输出通道，然后对整个 BEV 特征图进行卷积预测。具体解释如下：\n",
    "\n",
    "1. **raw_hm (热力图)**  \n",
    "   - 输出尺寸为 `[3, 448, 1120]`，其中 3 表示预测类别数（这里类别数为 3，比如 Vehicle、Pedestrian、Cyclist）。因此，每个类别对应一个通道，最终形成一个形状为 `[num_classes, H, W]` 的热力图。\n",
    "\n",
    "2. **raw_center (中心偏移)**  \n",
    "   - 输出尺寸为 `[2, 448, 1120]`，这里 2 通常表示在 BEV 特征图上，每个 grid cell 内的预测中心坐标（x 和 y 的残差）。即从离散的网格中心到真实中心的偏移。\n",
    "\n",
    "3. **raw_center_z (高度/中心z值)**  \n",
    "   - 输出尺寸为 `[1, 448, 1120]`，只有 1 个通道，用于预测目标在 z 轴方向上的位置（或者说目标的高度信息）。\n",
    "\n",
    "4. **raw_dim (尺寸)**  \n",
    "   - 输出尺寸为 `[3, 448, 1120]`，这里 3 个通道分别对应目标的长、宽、高（l, w, h）的预测值，通常预测的是对数尺度（后续可能会做 exp 处理）或者直接在 BEV 中的尺寸。\n",
    "\n",
    "5. **raw_rot (旋转角度)**  \n",
    "   - 输出尺寸为 `[2, 448, 1120]`，通常用两个通道分别表示旋转角度的 sin 和 cos 值，这样可以避免角度回归带来的周期性问题。\n",
    "\n",
    "**总结：**  \n",
    "- 每个分支的通道数即对应任务的输出数量。  \n",
    "- 448 和 1120 是 BEV 特征图的高度和宽度（由点云范围、voxel 大小和下采样系数决定）。  \n",
    "- 例如，hm 分支输出 3 个通道对应 3 个类别，中心偏移输出 2 个通道（x,y），中心高度（z）输出 1 个通道，尺寸输出 3 个通道，而旋转输出 2 个通道。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(pred, gt, alpha=1, beta=4):\n",
    "    \"\"\"\n",
    "    实现一个简单版本的 focal loss，\n",
    "    输入 pred 和 gt 均为 [num_classes, H, W] 的张量\n",
    "    pred 应该是经过 sigmoid 激活后的预测热力图\n",
    "    \"\"\"\n",
    "    assert(isinstance(pred,torch.Tensor))\n",
    "    assert(isinstance(gt, torch.Tensor))\n",
    "    \n",
    "    pos_inds = (gt == 1).float()\n",
    "    neg_inds = (gt < 1).float()\n",
    "\n",
    "    pos_loss = -torch.log(pred + 1e-4) * torch.pow(1 - pred, alpha) * pos_inds\n",
    "    neg_loss = -torch.log(1 - pred + 1e-4) * torch.pow(pred, alpha) * torch.pow(1 - gt, beta) * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.sum()\n",
    "    if num_pos == 0:\n",
    "        loss = neg_loss.sum()\n",
    "    else:\n",
    "        loss = (pos_loss.sum() + neg_loss.sum()) / num_pos\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_loss(pred_dicts, gt_dicts):\n",
    "    total_offset_loss = 0.0\n",
    "    total_height_loss = 0.0\n",
    "    batch_count = len(pred_dicts)\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        pred = pred_dicts[i]\n",
    "        gt = gt_dicts[i]\n",
    "        \n",
    "        raw_center = pred[\"raw_center\"]   # shape: [2, H, W]\n",
    "        _, H, W = raw_center.shape\n",
    "        raw_center_flat = raw_center.view(2, -1).transpose(0, 1)  # shape: [H*W, 2]\n",
    "        \n",
    "        raw_center_z = pred[\"raw_center_z\"]  # shape: [1, H, W]\n",
    "        raw_center_z_flat = raw_center_z.view(1, -1).transpose(0, 1)  # shape: [H*W, 1]\n",
    "        \n",
    "        # 确保索引为 long 类型\n",
    "        indices = gt[\"ind\"].to(torch.long)\n",
    "        if indices.nelement() > 0:\n",
    "            pred_offset = raw_center_flat[indices]  # shape: [N, 2]\n",
    "            pred_height = raw_center_z_flat[indices]  # shape: [N, 1]\n",
    "            \n",
    "            gt_offset = gt[\"reg\"]                 # shape: [N, 2]\n",
    "            gt_height = gt[\"height\"].unsqueeze(-1)  # shape: [N, 1]\n",
    "            reg_mask = gt[\"reg_mask\"].float()\n",
    "            num_valid = reg_mask.sum() + 1e-4\n",
    "\n",
    "            offset_loss = F.l1_loss(pred_offset, gt_offset, reduction=\"sum\") / num_valid\n",
    "            height_loss = F.l1_loss(pred_height, gt_height, reduction=\"sum\") / num_valid\n",
    "        else:\n",
    "            # 如果没有有效目标，则构造一个与预测相关联的零 loss 以便 backward 正常\n",
    "            offset_loss = raw_center_flat[0].sum() * 0.0\n",
    "            height_loss = raw_center_z_flat[0].sum() * 0.0\n",
    "        \n",
    "        total_offset_loss += offset_loss\n",
    "        total_height_loss += height_loss\n",
    "\n",
    "    avg_offset_loss = total_offset_loss / batch_count\n",
    "    avg_height_loss = total_height_loss / batch_count\n",
    "\n",
    "    return avg_offset_loss, avg_height_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lwh_loss(pred_dicts, gt_dicts):\n",
    "    \"\"\"\n",
    "    计算每个 batch (pred_dicts[i] 和 gt_dicts[i] 对应一个 batch) 的尺寸（长、宽、高）回归 L1 损失，\n",
    "    输入参数与 xyz_loss 完全一致。\n",
    "\n",
    "    pred_dicts: list，每个元素为一个 batch 的预测 dict，其中包含键:\n",
    "                - \"raw_dim\": 预测的尺寸张量，形状为 [3, H, W]\n",
    "    gt_dicts:   list，每个元素为一个 batch 的 GT dict，其中包含键:\n",
    "                - \"size\": GT 尺寸，形状为 [N, 3]  (包含长、宽和高)\n",
    "                - \"ind\":  每个有效目标在 BEV 下采样后的 flatten 索引，形状为 [N]\n",
    "                - \"reg_mask\": 有效目标的 mask，形状为 [N]\n",
    "\n",
    "    返回:\n",
    "       avg_size_loss: 平均尺寸回归损失（标量 tensor）\n",
    "    \"\"\"\n",
    "    total_size_loss = 0.0\n",
    "    batch_count = len(pred_dicts)\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        pred = pred_dicts[i]\n",
    "        gt = gt_dicts[i]\n",
    "        \n",
    "        # raw_dim: [3, H, W]\n",
    "        raw_dim = pred[\"raw_dim\"]\n",
    "        _, H, W = raw_dim.shape\n",
    "        # 扁平化为 [H*W, 3]\n",
    "        raw_dim_flat = raw_dim.view(3, -1).transpose(0, 1)\n",
    "        \n",
    "        # 确保 indices 为 long 类型\n",
    "        indices = gt[\"ind\"].to(torch.long)\n",
    "        \n",
    "        if indices.nelement() > 0:\n",
    "            # 从预测中采样出有效目标对应的尺寸预测： [N, 3]\n",
    "            pred_size = raw_dim_flat[indices]\n",
    "            gt_size = gt[\"size\"]  # [N, 3]\n",
    "            reg_mask = gt[\"reg_mask\"].float()\n",
    "            num_valid = reg_mask.sum() + 1e-4\n",
    "            \n",
    "            # 计算 L1 损失并归一化\n",
    "            loss_size = F.l1_loss(pred_size, gt_size, reduction=\"sum\") / num_valid\n",
    "        else:\n",
    "            # 若无有效目标，则返回与预测相关联的零 loss\n",
    "            loss_size = raw_dim_flat[0].sum() * 0.0\n",
    "        \n",
    "        total_size_loss += loss_size\n",
    "        \n",
    "    avg_size_loss = total_size_loss / batch_count\n",
    "    return avg_size_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_loss(pred_dicts, gt_dicts):\n",
    "    \"\"\"\n",
    "    计算每个 batch 的旋转回归 L1 损失，输入参数与 xyz_loss 和 lwh_loss 保持一致。\n",
    "    \n",
    "    输入：\n",
    "      pred_dicts: list，每个元素是一个 batch 的预测 dict，其中包含键：\n",
    "                  - \"raw_rot\": 预测的旋转张量，形状为 [2, H, W]，代表 sin 和 cos 的预测\n",
    "      gt_dicts:   list，每个元素是一个 batch 的 GT dict，其中包含键：\n",
    "                  - \"rot\": GT 的旋转角，形状为 [N]（标量角度）\n",
    "                  - \"ind\": GT 对应在 BEV 下采样后的 flatten 索引，形状为 [N]\n",
    "                  - \"reg_mask\": 有效目标 mask，形状为 [N]\n",
    "    \n",
    "    返回：\n",
    "      avg_rot_loss: 平均旋转回归损失（标量 tensor）\n",
    "    \"\"\"\n",
    "    total_rot_loss = 0.0\n",
    "    batch_count = len(pred_dicts)\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        pred = pred_dicts[i]\n",
    "        gt = gt_dicts[i]\n",
    "        \n",
    "        # raw_rot: [2, H, W] → flatten 成 [H*W, 2]\n",
    "        raw_rot = pred[\"raw_rot\"]\n",
    "        _, H, W = raw_rot.shape\n",
    "        raw_rot_flat = raw_rot.view(2, -1).transpose(0, 1)  # 形状: [H*W, 2]\n",
    "        \n",
    "        # 确保索引为 long 类型\n",
    "        indices = gt[\"ind\"].to(torch.long)\n",
    "        \n",
    "        if indices.nelement() > 0:\n",
    "            # 采样出预测的旋转值 [N, 2]\n",
    "            pred_rot = raw_rot_flat[indices]\n",
    "            \n",
    "            # GT 的旋转角以标量形式给出，转换为 sin 和 cos 组成的目标 [N, 2]\n",
    "            gt_rot = gt[\"rot\"].unsqueeze(-1)      # [N, 1]\n",
    "            gt_rot_targets = torch.cat([torch.sin(gt_rot), torch.cos(gt_rot)], dim=1)  # [N, 2]\n",
    "            \n",
    "            reg_mask = gt[\"reg_mask\"].float()\n",
    "            num_valid = reg_mask.sum() + 1e-4\n",
    "            \n",
    "            loss_rot = F.l1_loss(pred_rot, gt_rot_targets, reduction=\"sum\") / num_valid\n",
    "        else:\n",
    "            # 若无有效目标，则构造一个和预测相关联的零 loss，以确保 backward 时有 grad_fn\n",
    "            loss_rot = raw_rot_flat[0].sum() * 0.0\n",
    "        \n",
    "        total_rot_loss += loss_rot\n",
    "\n",
    "    avg_rot_loss = total_rot_loss / batch_count\n",
    "    return avg_rot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_heatmap_loss(pred_dicts, gt_dicts):\n",
    "    \"\"\"\n",
    "    计算每个 batch (pred_dicts[i] 与 gt_dicts[i] 对应一个 batch) 的 MSE 损失，\n",
    "    使得预测的热力图逼近 ground truth 热力图。\n",
    "\n",
    "    输入：\n",
    "      pred_dicts: list，每个元素为一个 batch 的预测 dict，其中包含键：\n",
    "                  - \"raw_hm\": 预测的热力图张量，形状为 [num_classes, H, W]\n",
    "      gt_dicts:   list，每个元素为一个 batch 的 GT dict，其中包含键：\n",
    "                  - \"heatmap\": GT 热力图，形状为 [num_classes, H, W]\n",
    "                  \n",
    "    返回：\n",
    "      avg_mse_loss: 每个 batch 的平均 MSE 损失（标量 tensor）\n",
    "    \"\"\"\n",
    "    total_mse_loss = 0.0\n",
    "    batch_count = len(pred_dicts)\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        pred = pred_dicts[i]\n",
    "        gt = gt_dicts[i]\n",
    "        \n",
    "        # 预测热力图 raw_hm 通常为未经过 sigmoid 的输出，\n",
    "        # 为了使其与 GT 热力图比较前先归一化到 [0,1]，这里用 sigmoid 处理\n",
    "        raw_hm = pred[\"raw_hm\"]  # shape: [num_classes, H, W]\n",
    "        pred_hm = torch.sigmoid(raw_hm)   # shape: [num_classes, H, W]\n",
    "        \n",
    "        gt_hm = gt[\"heatmap\"]             # shape: [num_classes, H, W]\n",
    "        \n",
    "        # 计算均方误差（MSE）损失，这里 reduction 选 \"mean\" 表示取所有像素的平均值\n",
    "        mse_loss = F.mse_loss(pred_hm, gt_hm, reduction=\"mean\")\n",
    "        total_mse_loss += mse_loss\n",
    "    \n",
    "    avg_mse_loss = total_mse_loss / batch_count\n",
    "    return avg_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred_dicts, gt_dicts):\n",
    "    \"\"\"\n",
    "    计算每个 batch（pred_dicts[i] 和 gt_dicts[i] 对应一批）的 focal loss，\n",
    "    然后求平均总损失。\n",
    "\n",
    "    输入：\n",
    "      pred_dicts: list，每个元素为一个 batch 的预测 dict，\n",
    "                   其中包含键 'raw_hm'，形状为 [num_classes, H, W]\n",
    "      gt_dicts:   list，每个元素为一个 batch 的 GT dict，\n",
    "                   其中包含键 'heatmap'，形状为 [num_classes, H, W]\n",
    "\n",
    "    返回：\n",
    "      平均 focal loss（标量 tensor）\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    fc_ = 0.0\n",
    "    xyz_ = 0.0\n",
    "    lwh_ = 0.0\n",
    "    rot_ = 0.0\n",
    "    \n",
    "    batch_count = len(pred_dicts)\n",
    "    for i in range(batch_count):\n",
    "        # print(f\"计算第{i+1}个batch的 focal loss ...\")\n",
    "        # 获取该 batch 的预测热力图，注意需要先经过 sigmoid\n",
    "        \n",
    "        ######## 1 计算 focal loss ###########\n",
    "        # pred_hm = torch.sigmoid(pred_dicts[i][\"raw_hm\"])  # [num_classes, H, W]\n",
    "        # gt_hm = gt_dicts[i][\"heatmap\"]                    # [num_classes, H, W]\n",
    "\n",
    "        # fc_loss = focal_loss(pred_hm, gt_hm)\n",
    "        # total_loss += fc_loss\n",
    "        # fc_ += fc_loss\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        ######## 2 计算 xyz loss #############\n",
    "        xy_loss,z_loss = xyz_loss(pred_dicts,gt_dicts)\n",
    "        total_loss += xy_loss + z_loss\n",
    "        xyz_ += xy_loss + z_loss\n",
    "        ###################################\n",
    "        \n",
    "        ######## 3 计算 lwh loss #############\n",
    "        lwh_loss_ = lwh_loss(pred_dicts,gt_dicts)\n",
    "        total_loss += lwh_loss_\n",
    "        lwh_ += lwh_loss_\n",
    "        ###################################\n",
    "        \n",
    "        ######## 4 计算 rot loss #############\n",
    "        rot_loss_ = rot_loss(pred_dicts,gt_dicts)\n",
    "        total_loss += rot_loss_\n",
    "        rot_ += rot_loss_\n",
    "        ###################################\n",
    "        \n",
    "        ####### 5 计算 Heatmap MSE loss ######\n",
    "        total_loss += mse_heatmap_loss(pred_dicts,gt_dicts)\n",
    "        #####################################\n",
    "\n",
    "    avg_loss = total_loss / batch_count\n",
    "    avg_fc = fc_ / batch_count\n",
    "    avg_xyz = xyz_ / batch_count\n",
    "    avg_lwh = lwh_ / batch_count\n",
    "    avg_rot = rot_ / batch_count\n",
    "    \n",
    "    return dict(\n",
    "      total_loss = avg_loss,\n",
    "      fc_loss = avg_fc,\n",
    "      xyz_loss = avg_xyz,\n",
    "      lwh_loss = avg_lwh,\n",
    "      rot_loss = avg_rot\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 定义Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_metrics(pred_dicts, gt_dicts, center_thresh=2.0):\n",
    "    \"\"\"\n",
    "    计算每个 batch 的检测评估指标，包含：\n",
    "      - total_pred: 预测候选框总数\n",
    "      - total_gt:   GT 框总数\n",
    "      - total_matches: 成功匹配的 GT 框数\n",
    "      - avg_center_error: 匹配成功时中心位置的平均欧氏距离误差（仅基于 (x,y) 坐标）\n",
    "      - cls_accuracy: 匹配成功中预测类别正确的比率\n",
    "      - true_match: 匹配成功的预测框占总预测框的比例\n",
    "      - gt_box_recall: 匹配成功的 GT 框占总 GT 框的比例\n",
    "\n",
    "    匹配策略（简单策略）：\n",
    "      对于每个 GT 框（使用其 (x,y) 中心），计算与所有预测框中心之间的欧氏距离，\n",
    "      选择距离最小的预测框；若最小距离小于 center_thresh 且该预测框未被其它 GT 框匹配，则认为匹配成功。\n",
    "\n",
    "    输入：\n",
    "      pred_dicts: list，每个元素为一个 batch 的预测 dict，其中必须包含：\n",
    "                  - \"pred_boxes\": [N_pred, 7]，预测的 3D 框（格式：x, y, z, l, w, h, rot）\n",
    "                  - \"pred_labels\": [N_pred]，预测的类别标签\n",
    "      gt_dicts:   list，每个元素为一个 batch 的 GT dict，其中必须包含：\n",
    "                  - \"gt_boxes\": [N_gt, 7]，GT 框，格式同上\n",
    "                  - \"gt_labels\": [N_gt]，GT 类别标签\n",
    "    参数：\n",
    "      center_thresh: 匹配阈值，单位与 box 中 x,y 坐标一致（例如米）\n",
    "\n",
    "    返回：\n",
    "      metrics: dict，包含上述各项指标，其中还额外添加了：\n",
    "               - \"true_match\": total_matches / total_pred (预测匹配率)\n",
    "               - \"gt_box_recall\": total_matches / total_gt (GT 框的召回率)\n",
    "    \"\"\"\n",
    "    total_matches = 0\n",
    "    correct_cls = 0\n",
    "    total_center_error = 0.0\n",
    "    total_pred = 0\n",
    "    total_gt = 0\n",
    "    batch_count = len(pred_dicts)\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        pred = pred_dicts[i]\n",
    "        gt = gt_dicts[i]\n",
    "        \n",
    "        # 获取预测和 GT 的 box 与标签\n",
    "        pred_boxes = pred.get(\"pred_boxes\", torch.empty((0, 7)))  # [N_pred, 7]\n",
    "        pred_labels = pred.get(\"pred_labels\", torch.empty((0,), dtype=torch.long))  # [N_pred]\n",
    "        gt_boxes = gt.get(\"gt_boxes\", torch.empty((0, 7)))\n",
    "        gt_labels = gt.get(\"gt_labels\", torch.empty((0,), dtype=torch.long))\n",
    "        \n",
    "        total_pred += pred_boxes.shape[0]\n",
    "        total_gt += gt_boxes.shape[0]\n",
    "        \n",
    "        # 为简单起见，这里只计算 (x, y) 坐标之间的距离\n",
    "        matched_pred = set()  # 用于记录已经匹配的预测索引，保证一对一匹配\n",
    "        for j in range(gt_boxes.shape[0]):\n",
    "            gt_box = gt_boxes[j]\n",
    "            gt_center = gt_box[:2]  # 取 GT 的 x,y 中心\n",
    "            if pred_boxes.shape[0] == 0:\n",
    "                continue\n",
    "            # 预测框的中心也是取前两个数\n",
    "            pred_centers = pred_boxes[:, :2]  # [N_pred, 2]\n",
    "            # 计算每个预测与 GT 的欧氏距离\n",
    "            dists = torch.norm(pred_centers - gt_center.unsqueeze(0), dim=1)\n",
    "            min_val, min_idx = dists.min(0)\n",
    "            if min_val.item() < center_thresh and min_idx.item() not in matched_pred:\n",
    "                total_matches += 1\n",
    "                total_center_error += min_val.item()\n",
    "                if pred_labels[min_idx] == gt_labels[j]:\n",
    "                    correct_cls += 1\n",
    "                matched_pred.add(min_idx.item())\n",
    "    \n",
    "    if total_matches > 0:\n",
    "        avg_center_error = total_center_error / total_matches\n",
    "        cls_accuracy = correct_cls / total_matches\n",
    "    else:\n",
    "        avg_center_error = 0.0\n",
    "        cls_accuracy = 0.0\n",
    "\n",
    "    # 计算额外的指标, 注意避免除以 0\n",
    "    true_match = total_matches / total_pred if total_pred > 0 else 0.0\n",
    "    gt_box_recall = total_matches / total_gt if total_gt > 0 else 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        \"total_pred\": total_pred,\n",
    "        \"total_gt\": total_gt,\n",
    "        \"total_matches\": total_matches,\n",
    "        \"avg_center_error\": avg_center_error,\n",
    "        \"cls_accuracy\": cls_accuracy,\n",
    "        \"true_match\": true_match,\n",
    "        \"gt_box_recall\": gt_box_recall\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = [0.2, 0.2, 0.2]\n",
    "feature_map_stride = 1\n",
    "num_classes = 3\n",
    "batch_size = 1\n",
    "pc_range = [0, -44.8, -2, 224, 44.8, 4]\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "dataset = PointCloudDataset(debug=False,\n",
    "                            voxel_size=voxel_size,\n",
    "                            feature_map_stride=feature_map_stride,\n",
    "                            pc_range=pc_range,\n",
    "                            num_classes=num_classes)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=False,collate_fn=myfunc,drop_last=True)\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False,collate_fn=myfunc,drop_last=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 这行注释掉\n",
    "\n",
    "model = CenterPoint(\n",
    "    voxel_size=voxel_size,\n",
    "    pc_range=pc_range,\n",
    "    feature_map_stride=feature_map_stride,\n",
    "    ).to(device)\n",
    "\n",
    "torch.cuda.empty_cache()  \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]['gt_boxes'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/80], Total Loss: 32.9584, FC Loss: 0.0000, XYZ Loss: 4.8522, LWH Loss: 26.3080, Rot Loss: 1.5694\n",
      "Epoch [1/100], Step [20/80], Total Loss: 33.2658, FC Loss: 0.0000, XYZ Loss: 3.7111, LWH Loss: 27.7019, Rot Loss: 1.6271\n",
      "Epoch [1/100], Step [30/80], Total Loss: 33.1203, FC Loss: 0.0000, XYZ Loss: 3.6411, LWH Loss: 27.6574, Rot Loss: 1.6003\n",
      "Epoch [1/100], Step [40/80], Total Loss: 32.7973, FC Loss: 0.0000, XYZ Loss: 3.3769, LWH Loss: 27.6272, Rot Loss: 1.5763\n",
      "Epoch [1/100], Step [50/80], Total Loss: 34.1637, FC Loss: 0.0000, XYZ Loss: 4.0029, LWH Loss: 28.3760, Rot Loss: 1.5722\n",
      "Epoch [1/100], Step [60/80], Total Loss: 33.4046, FC Loss: 0.0000, XYZ Loss: 3.7768, LWH Loss: 27.8663, Rot Loss: 1.5536\n",
      "Epoch [1/100], Step [70/80], Total Loss: 33.4870, FC Loss: 0.0000, XYZ Loss: 3.6586, LWH Loss: 28.0649, Rot Loss: 1.5596\n",
      "Epoch [1/100], Step [80/80], Total Loss: 33.2568, FC Loss: 0.0000, XYZ Loss: 3.8310, LWH Loss: 27.6794, Rot Loss: 1.5466\n",
      "Epoch [1/100], Average Total Loss: 33.2568, Average FC Loss: 0.0000, Average XYZ Loss: 3.8310, Average LWH Loss: 27.6794, Average Rot Loss: 1.5466\n",
      "Epoch [1/100] Validation Loss: 30.2834\n",
      "Validation detection metrics: {'total_pred': 82.65, 'total_gt': 25.55, 'total_matches': 0.15, 'avg_center_error': 0.07461695820093155, 'cls_accuracy': 0.0, 'true_match': 0.0018768115942028984, 'gt_box_recall': 0.004112903225806452}\n",
      "Epoch [2/100], Step [10/80], Total Loss: 29.1297, FC Loss: 0.0000, XYZ Loss: 3.5782, LWH Loss: 23.9901, Rot Loss: 1.4004\n",
      "Epoch [2/100], Step [20/80], Total Loss: 29.7714, FC Loss: 0.0000, XYZ Loss: 2.6664, LWH Loss: 25.5951, Rot Loss: 1.3498\n",
      "Epoch [2/100], Step [30/80], Total Loss: 29.9526, FC Loss: 0.0000, XYZ Loss: 2.7072, LWH Loss: 25.6522, Rot Loss: 1.4387\n",
      "Epoch [2/100], Step [40/80], Total Loss: 29.6921, FC Loss: 0.0000, XYZ Loss: 2.4979, LWH Loss: 25.5687, Rot Loss: 1.4757\n",
      "Epoch [2/100], Step [50/80], Total Loss: 30.9265, FC Loss: 0.0000, XYZ Loss: 3.1840, LWH Loss: 26.1124, Rot Loss: 1.4855\n",
      "Epoch [2/100], Step [60/80], Total Loss: 30.3033, FC Loss: 0.0000, XYZ Loss: 3.0127, LWH Loss: 25.6889, Rot Loss: 1.4630\n",
      "Epoch [2/100], Step [70/80], Total Loss: 30.2842, FC Loss: 0.0000, XYZ Loss: 2.9394, LWH Loss: 25.7496, Rot Loss: 1.4622\n",
      "Epoch [2/100], Step [80/80], Total Loss: 30.0109, FC Loss: 0.0000, XYZ Loss: 3.1257, LWH Loss: 25.3253, Rot Loss: 1.4323\n",
      "Epoch [2/100], Average Total Loss: 30.0109, Average FC Loss: 0.0000, Average XYZ Loss: 3.1257, Average LWH Loss: 25.3253, Average Rot Loss: 1.4323\n",
      "Epoch [2/100] Validation Loss: 29.3802\n",
      "Validation detection metrics: {'total_pred': 98.0, 'total_gt': 25.55, 'total_matches': 0.0, 'avg_center_error': 0.0, 'cls_accuracy': 0.0, 'true_match': 0.0, 'gt_box_recall': 0.0}\n",
      "Epoch [3/100], Step [10/80], Total Loss: 26.9569, FC Loss: 0.0000, XYZ Loss: 3.5920, LWH Loss: 21.7576, Rot Loss: 1.5312\n",
      "Epoch [3/100], Step [20/80], Total Loss: 27.2156, FC Loss: 0.0000, XYZ Loss: 2.5912, LWH Loss: 23.0750, Rot Loss: 1.4754\n",
      "Epoch [3/100], Step [30/80], Total Loss: 26.8462, FC Loss: 0.0000, XYZ Loss: 2.4470, LWH Loss: 22.8564, Rot Loss: 1.4758\n",
      "Epoch [3/100], Step [40/80], Total Loss: 26.0615, FC Loss: 0.0000, XYZ Loss: 2.1790, LWH Loss: 22.3663, Rot Loss: 1.4547\n",
      "Epoch [3/100], Step [50/80], Total Loss: 26.9621, FC Loss: 0.0000, XYZ Loss: 2.8420, LWH Loss: 22.6207, Rot Loss: 1.4428\n",
      "Epoch [3/100], Step [60/80], Total Loss: 26.4262, FC Loss: 0.0000, XYZ Loss: 2.6453, LWH Loss: 22.2913, Rot Loss: 1.4381\n",
      "Epoch [3/100], Step [70/80], Total Loss: 26.4041, FC Loss: 0.0000, XYZ Loss: 2.6023, LWH Loss: 22.3134, Rot Loss: 1.4415\n",
      "Epoch [3/100], Step [80/80], Total Loss: 26.1578, FC Loss: 0.0000, XYZ Loss: 2.7851, LWH Loss: 21.9094, Rot Loss: 1.4197\n",
      "Epoch [3/100], Average Total Loss: 26.1578, Average FC Loss: 0.0000, Average XYZ Loss: 2.7851, Average LWH Loss: 21.9094, Average Rot Loss: 1.4197\n",
      "Epoch [3/100] Validation Loss: 27.1836\n",
      "Validation detection metrics: {'total_pred': 65.9, 'total_gt': 25.55, 'total_matches': 0.0, 'avg_center_error': 0.0, 'cls_accuracy': 0.0, 'true_match': 0.0, 'gt_box_recall': 0.0}\n",
      "Epoch [4/100], Step [10/80], Total Loss: 22.7223, FC Loss: 0.0000, XYZ Loss: 3.0184, LWH Loss: 18.3579, Rot Loss: 1.3330\n",
      "Epoch [4/100], Step [20/80], Total Loss: 23.1210, FC Loss: 0.0000, XYZ Loss: 2.1269, LWH Loss: 19.6806, Rot Loss: 1.3003\n",
      "Epoch [4/100], Step [30/80], Total Loss: 22.6375, FC Loss: 0.0000, XYZ Loss: 2.0286, LWH Loss: 19.3304, Rot Loss: 1.2665\n",
      "Epoch [4/100], Step [40/80], Total Loss: 22.0342, FC Loss: 0.0000, XYZ Loss: 1.8078, LWH Loss: 18.9223, Rot Loss: 1.2935\n",
      "Epoch [4/100], Step [50/80], Total Loss: 22.9777, FC Loss: 0.0000, XYZ Loss: 2.4954, LWH Loss: 19.1852, Rot Loss: 1.2875\n",
      "Epoch [4/100], Step [60/80], Total Loss: 22.5215, FC Loss: 0.0000, XYZ Loss: 2.3315, LWH Loss: 18.9007, Rot Loss: 1.2805\n",
      "Epoch [4/100], Step [70/80], Total Loss: 22.6741, FC Loss: 0.0000, XYZ Loss: 2.2891, LWH Loss: 19.0415, Rot Loss: 1.3355\n",
      "Epoch [4/100], Step [80/80], Total Loss: 22.6156, FC Loss: 0.0000, XYZ Loss: 2.4824, LWH Loss: 18.8134, Rot Loss: 1.3123\n",
      "Epoch [4/100], Average Total Loss: 22.6156, Average FC Loss: 0.0000, Average XYZ Loss: 2.4824, Average LWH Loss: 18.8134, Average Rot Loss: 1.3123\n",
      "Epoch [4/100] Validation Loss: 21.6921\n",
      "Validation detection metrics: {'total_pred': 27.9, 'total_gt': 25.55, 'total_matches': 0.05, 'avg_center_error': 0.03563331663608551, 'cls_accuracy': 0.0, 'true_match': 0.0016666666666666666, 'gt_box_recall': 0.0016129032258064516}\n",
      "Epoch [5/100], Step [10/80], Total Loss: 19.4532, FC Loss: 0.0000, XYZ Loss: 2.8523, LWH Loss: 15.3267, Rot Loss: 1.2716\n",
      "Epoch [5/100], Step [20/80], Total Loss: 20.0255, FC Loss: 0.0000, XYZ Loss: 1.9869, LWH Loss: 16.7926, Rot Loss: 1.2436\n",
      "Epoch [5/100], Step [30/80], Total Loss: 19.6986, FC Loss: 0.0000, XYZ Loss: 1.9305, LWH Loss: 16.5412, Rot Loss: 1.2246\n",
      "Epoch [5/100], Step [40/80], Total Loss: 20.4284, FC Loss: 0.0000, XYZ Loss: 1.8112, LWH Loss: 17.3906, Rot Loss: 1.2243\n",
      "Epoch [5/100], Step [50/80], Total Loss: 21.4557, FC Loss: 0.0000, XYZ Loss: 2.4734, LWH Loss: 17.7524, Rot Loss: 1.2277\n",
      "Epoch [5/100], Step [60/80], Total Loss: 20.9896, FC Loss: 0.0000, XYZ Loss: 2.2907, LWH Loss: 17.4671, Rot Loss: 1.2296\n",
      "Epoch [5/100], Step [70/80], Total Loss: 21.0968, FC Loss: 0.0000, XYZ Loss: 2.2342, LWH Loss: 17.6347, Rot Loss: 1.2258\n",
      "Epoch [5/100], Step [80/80], Total Loss: 21.0390, FC Loss: 0.0000, XYZ Loss: 2.4193, LWH Loss: 17.4090, Rot Loss: 1.2086\n",
      "Epoch [5/100], Average Total Loss: 21.0390, Average FC Loss: 0.0000, Average XYZ Loss: 2.4193, Average LWH Loss: 17.4090, Average Rot Loss: 1.2086\n",
      "Epoch [5/100] Validation Loss: 19.5352\n",
      "Validation detection metrics: {'total_pred': 11.3, 'total_gt': 25.55, 'total_matches': 0.0, 'avg_center_error': 0.0, 'cls_accuracy': 0.0, 'true_match': 0.0, 'gt_box_recall': 0.0}\n",
      "Epoch [6/100], Step [10/80], Total Loss: 18.6676, FC Loss: 0.0000, XYZ Loss: 2.8612, LWH Loss: 14.6136, Rot Loss: 1.1913\n",
      "Epoch [6/100], Step [20/80], Total Loss: 18.9486, FC Loss: 0.0000, XYZ Loss: 1.9879, LWH Loss: 15.7582, Rot Loss: 1.2011\n",
      "Epoch [6/100], Step [30/80], Total Loss: 18.7881, FC Loss: 0.0000, XYZ Loss: 1.9213, LWH Loss: 15.6544, Rot Loss: 1.2110\n",
      "Epoch [6/100], Step [40/80], Total Loss: 18.4941, FC Loss: 0.0000, XYZ Loss: 1.7062, LWH Loss: 15.5683, Rot Loss: 1.2182\n",
      "Epoch [6/100], Step [50/80], Total Loss: 19.5968, FC Loss: 0.0000, XYZ Loss: 2.3825, LWH Loss: 15.9809, Rot Loss: 1.2322\n",
      "Epoch [6/100], Step [60/80], Total Loss: 19.1939, FC Loss: 0.0000, XYZ Loss: 2.2138, LWH Loss: 15.7485, Rot Loss: 1.2304\n",
      "Epoch [6/100], Step [70/80], Total Loss: 19.6995, FC Loss: 0.0000, XYZ Loss: 2.2365, LWH Loss: 16.2267, Rot Loss: 1.2351\n",
      "Epoch [6/100], Step [80/80], Total Loss: 19.6755, FC Loss: 0.0000, XYZ Loss: 2.4310, LWH Loss: 16.0291, Rot Loss: 1.2143\n",
      "Epoch [6/100], Average Total Loss: 19.6755, Average FC Loss: 0.0000, Average XYZ Loss: 2.4310, Average LWH Loss: 16.0291, Average Rot Loss: 1.2143\n",
      "Epoch [6/100] Validation Loss: 17.5069\n",
      "Validation detection metrics: {'total_pred': 4.5, 'total_gt': 25.55, 'total_matches': 0.0, 'avg_center_error': 0.0, 'cls_accuracy': 0.0, 'true_match': 0.0, 'gt_box_recall': 0.0}\n",
      "Epoch [7/100], Step [10/80], Total Loss: 17.3611, FC Loss: 0.0000, XYZ Loss: 2.8752, LWH Loss: 13.2618, Rot Loss: 1.2234\n",
      "Epoch [7/100], Step [20/80], Total Loss: 17.6741, FC Loss: 0.0000, XYZ Loss: 1.9504, LWH Loss: 14.5268, Rot Loss: 1.1961\n",
      "Epoch [7/100], Step [30/80], Total Loss: 17.6828, FC Loss: 0.0000, XYZ Loss: 1.8772, LWH Loss: 14.6206, Rot Loss: 1.1842\n",
      "Epoch [7/100], Step [40/80], Total Loss: 17.1404, FC Loss: 0.0000, XYZ Loss: 1.6478, LWH Loss: 14.3026, Rot Loss: 1.1893\n",
      "Epoch [7/100], Step [50/80], Total Loss: 18.2159, FC Loss: 0.0000, XYZ Loss: 2.3201, LWH Loss: 14.6942, Rot Loss: 1.2008\n",
      "Epoch [7/100], Step [60/80], Total Loss: 17.9229, FC Loss: 0.0000, XYZ Loss: 2.1571, LWH Loss: 14.5661, Rot Loss: 1.1989\n",
      "Epoch [7/100], Step [70/80], Total Loss: 18.1480, FC Loss: 0.0000, XYZ Loss: 2.1003, LWH Loss: 14.8514, Rot Loss: 1.1956\n",
      "Epoch [7/100], Step [80/80], Total Loss: 18.1552, FC Loss: 0.0000, XYZ Loss: 2.2930, LWH Loss: 14.6880, Rot Loss: 1.1735\n",
      "Epoch [7/100], Average Total Loss: 18.1552, Average FC Loss: 0.0000, Average XYZ Loss: 2.2930, Average LWH Loss: 14.6880, Average Rot Loss: 1.1735\n",
      "Epoch [7/100] Validation Loss: 16.9732\n",
      "Validation detection metrics: {'total_pred': 4.35, 'total_gt': 25.55, 'total_matches': 0.0, 'avg_center_error': 0.0, 'cls_accuracy': 0.0, 'true_match': 0.0, 'gt_box_recall': 0.0}\n",
      "Epoch [8/100], Step [10/80], Total Loss: 16.6270, FC Loss: 0.0000, XYZ Loss: 2.7722, LWH Loss: 12.7158, Rot Loss: 1.1386\n",
      "Epoch [8/100], Step [20/80], Total Loss: 16.8340, FC Loss: 0.0000, XYZ Loss: 1.8751, LWH Loss: 13.8069, Rot Loss: 1.1516\n",
      "Epoch [8/100], Step [30/80], Total Loss: 16.7859, FC Loss: 0.0000, XYZ Loss: 1.8109, LWH Loss: 13.8388, Rot Loss: 1.1358\n",
      "Epoch [8/100], Step [40/80], Total Loss: 16.3153, FC Loss: 0.0000, XYZ Loss: 1.6127, LWH Loss: 13.5477, Rot Loss: 1.1545\n",
      "Epoch [8/100], Step [50/80], Total Loss: 17.1673, FC Loss: 0.0000, XYZ Loss: 2.2889, LWH Loss: 13.7115, Rot Loss: 1.1665\n",
      "Epoch [8/100], Step [60/80], Total Loss: 16.9871, FC Loss: 0.0000, XYZ Loss: 2.1246, LWH Loss: 13.6970, Rot Loss: 1.1651\n",
      "Epoch [8/100], Step [70/80], Total Loss: 17.2870, FC Loss: 0.0000, XYZ Loss: 2.0596, LWH Loss: 14.0649, Rot Loss: 1.1621\n",
      "Epoch [8/100], Step [80/80], Total Loss: 17.3524, FC Loss: 0.0000, XYZ Loss: 2.2591, LWH Loss: 13.9480, Rot Loss: 1.1449\n",
      "Epoch [8/100], Average Total Loss: 17.3524, Average FC Loss: 0.0000, Average XYZ Loss: 2.2591, Average LWH Loss: 13.9480, Average Rot Loss: 1.1449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m val_pointclouds \u001b[38;5;241m=\u001b[39m move_to_gpu(val_pointclouds)\n\u001b[1;32m     56\u001b[0m val_gt_dicts \u001b[38;5;241m=\u001b[39m move_to_gpu(val_gt_dicts)\n\u001b[0;32m---> 58\u001b[0m pred_dicts_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_pointclouds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m loss_dict_val \u001b[38;5;241m=\u001b[39m compute_loss(pred_dicts_val, val_gt_dicts)\n\u001b[1;32m     61\u001b[0m val_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_dict_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/workspace/git/3D-Detection/det3d/models/centerpoint/centerpoint.py:20\u001b[0m, in \u001b[0;36mCenterPoint.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m B,_,D \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,D)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minter_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/workspace/git/3D-Detection/det3d/models/centerpoint/ld_base_v1.py:34\u001b[0m, in \u001b[0;36mLD_base.forward\u001b[0;34m(self, batch_dict)\u001b[0m\n\u001b[1;32m     32\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_to_bev(batch_dict)\n\u001b[1;32m     33\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(batch_dict)\n\u001b[0;32m---> 34\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_box_dicts\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/workspace/git/3D-Detection/det3d/models/centerpoint/centerhead.py:298\u001b[0m, in \u001b[0;36mCenterHead.forward\u001b[0;34m(self, data_dict)\u001b[0m\n\u001b[1;32m    294\u001b[0m     pred_dicts\u001b[38;5;241m.\u001b[39mappend(head(x))\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_ret_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_dicts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred_dicts\n\u001b[0;32m--> 298\u001b[0m pred_dicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_predicted_boxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_dicts\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_box_dicts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred_dicts\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_dict\n",
      "File \u001b[0;32m/workspace/git/3D-Detection/det3d/models/centerpoint/centerhead.py:214\u001b[0m, in \u001b[0;36mCenterHead.generate_predicted_boxes\u001b[0;34m(self, batch_size, pred_dicts)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_predicted_boxes\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size, pred_dicts):\n\u001b[1;32m    213\u001b[0m     post_process_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPOST_PROCESSING\n\u001b[0;32m--> 214\u001b[0m     post_center_limit_range \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_process_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST_CENTER_LIMIT_RANGE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    216\u001b[0m     ret_dict \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_boxes\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_labels\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m    220\u001b[0m     } \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)]\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, pred_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pred_dicts):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 训练模式\n",
    "    running_loss = 0.0\n",
    "    running_fc = 0.0\n",
    "    running_xyz = 0.0\n",
    "    running_lwh = 0.0\n",
    "    running_rot = 0.0\n",
    "\n",
    "    for i, (pointclouds, gt_dicts, lengths) in enumerate(trainloader):\n",
    "        # 将点云和 GT 数据移到 GPU（或者本来就在对应设备上）\n",
    "        pointclouds = move_to_gpu(pointclouds)\n",
    "        gt_dicts = move_to_gpu(gt_dicts)\n",
    "        \n",
    "        # 可以调试打印 GT 信息的尺寸\n",
    "        # print_dict_tensors_size(gt_dicts)\n",
    "        \n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        pred_dicts = model(pointclouds)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss_dict = compute_loss(pred_dicts, gt_dicts)\n",
    "        loss = loss_dict['total_loss']\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 参数更新\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # running_fc += loss_dict['fc_loss'].item()\n",
    "        running_xyz += loss_dict['xyz_loss'].item()\n",
    "        running_lwh += loss_dict['lwh_loss'].item()\n",
    "        running_rot += loss_dict['rot_loss'].item()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], \"\n",
    "                  f\"Total Loss: {running_loss/(i+1):.4f}, FC Loss: {running_fc/(i+1):.4f}, \"\n",
    "                  f\"XYZ Loss: {running_xyz/(i+1):.4f}, LWH Loss: {running_lwh/(i+1):.4f}, \"\n",
    "                  f\"Rot Loss: {running_rot/(i+1):.4f}\")\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Total Loss: {running_loss/len(trainloader):.4f}, \"\n",
    "          f\"Average FC Loss: {running_fc/len(trainloader):.4f}, Average XYZ Loss: {running_xyz/len(trainloader):.4f}, \"\n",
    "          f\"Average LWH Loss: {running_lwh/len(trainloader):.4f}, Average Rot Loss: {running_rot/len(trainloader):.4f}\")\n",
    "    \n",
    "    # ===========================\n",
    "    # Evaluation 阶段：在验证集上计算损失和检测指标\n",
    "    # ===========================\n",
    "    model.eval()  # 设置为验证模式\n",
    "    val_loss_total = 0.0\n",
    "    val_batches = 0\n",
    "    # 额外统计检测指标（使用你之前实现的 detection_metrics 函数）\n",
    "    all_metrics = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j, (val_pointclouds, val_gt_dicts, val_lengths) in enumerate(testloader):\n",
    "            val_pointclouds = move_to_gpu(val_pointclouds)\n",
    "            val_gt_dicts = move_to_gpu(val_gt_dicts)\n",
    "            \n",
    "            pred_dicts_val = model(val_pointclouds)\n",
    "            \n",
    "            loss_dict_val = compute_loss(pred_dicts_val, val_gt_dicts)\n",
    "            val_loss_total += loss_dict_val['total_loss'].item()\n",
    "            val_batches += 1\n",
    "            \n",
    "            # 计算检测指标\n",
    "            batch_metrics = detection_metrics(pred_dicts_val, val_gt_dicts, center_thresh=1.0)\n",
    "            all_metrics.append(batch_metrics)\n",
    "    \n",
    "    avg_val_loss = val_loss_total / val_batches if val_batches > 0 else 0.0\n",
    "    \n",
    "    # 这里对检测指标做一个简单的平均处理（对每个指标求平均）\n",
    "    if len(all_metrics) > 0:\n",
    "        avg_metrics = {}\n",
    "        keys = all_metrics[0].keys()\n",
    "        for key in keys:\n",
    "            avg_metrics[key] = sum(m[key] for m in all_metrics) / len(all_metrics)\n",
    "    else:\n",
    "        avg_metrics = {}\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(\"Validation detection metrics:\", avg_metrics)\n",
    "    \n",
    "    # 切换回训练模式（下一 epoch）\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''WANDDB\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import wandb  # pip install wandb\n",
    "from pprint import pprint\n",
    "\n",
    "# 初始化 wandb，指定项目名称和一些配置参数\n",
    "wandb.init(project=\"your_project_name\", config={\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    # 其它配置...\n",
    "})\n",
    "\n",
    "# 如果你之前用 move_to_gpu 函数，此处不需要修改\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 训练模式\n",
    "    running_loss = 0.0\n",
    "    running_fc = 0.0\n",
    "    running_xyz = 0.0\n",
    "    running_lwh = 0.0\n",
    "    running_rot = 0.0\n",
    "\n",
    "    for i, (pointclouds, gt_dicts, lengths) in enumerate(trainloader):\n",
    "        pointclouds = move_to_gpu(pointclouds)\n",
    "        gt_dicts = move_to_gpu(gt_dicts)\n",
    "        \n",
    "        # 可以打印 GT 信息尺寸以作调试\n",
    "        # print_dict_tensors_size(gt_dicts)\n",
    "        \n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        pred_dicts = model(pointclouds)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss_dict = compute_loss(pred_dicts, gt_dicts)\n",
    "        loss = loss_dict['total_loss']\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_fc += loss_dict['fc_loss'].item()\n",
    "        running_xyz += loss_dict['xyz_loss'].item()\n",
    "        running_lwh += loss_dict['lwh_loss'].item()\n",
    "        running_rot += loss_dict['rot_loss'].item()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            # 打印当前平均损失\n",
    "            avg_total = running_loss / (i+1)\n",
    "            avg_fc = running_fc / (i+1)\n",
    "            avg_xyz = running_xyz / (i+1)\n",
    "            avg_lwh = running_lwh / (i+1)\n",
    "            avg_rot = running_rot / (i+1)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], \"\n",
    "                  f\"Total Loss: {avg_total:.4f}, FC Loss: {avg_fc:.4f}, \"\n",
    "                  f\"XYZ Loss: {avg_xyz:.4f}, LWH Loss: {avg_lwh:.4f}, Rot Loss: {avg_rot:.4f}\")\n",
    "            \n",
    "            # 同步记录到 wandb\n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch + 1,\n",
    "                \"Step\": i + 1,\n",
    "                \"Total Loss\": avg_total,\n",
    "                \"FC Loss\": avg_fc,\n",
    "                \"XYZ Loss\": avg_xyz,\n",
    "                \"LWH Loss\": avg_lwh,\n",
    "                \"Rot Loss\": avg_rot\n",
    "            }, step=epoch * len(trainloader) + i)\n",
    "\n",
    "    avg_total_epoch = running_loss / len(trainloader)\n",
    "    avg_fc_epoch = running_fc / len(trainloader)\n",
    "    avg_xyz_epoch = running_xyz / len(trainloader)\n",
    "    avg_lwh_epoch = running_lwh / len(trainloader)\n",
    "    avg_rot_epoch = running_rot / len(trainloader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Total Loss: {avg_total_epoch:.4f}, \"\n",
    "          f\"FC Loss: {avg_fc_epoch:.4f}, XYZ Loss: {avg_xyz_epoch:.4f}, \"\n",
    "          f\"LWH Loss: {avg_lwh_epoch:.4f}, Rot Loss: {avg_rot_epoch:.4f}\")\n",
    "    \n",
    "    # 每个 epoch 后记录一次\n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Average Total Loss\": avg_total_epoch,\n",
    "        \"Average FC Loss\": avg_fc_epoch,\n",
    "        \"Average XYZ Loss\": avg_xyz_epoch,\n",
    "        \"Average LWH Loss\": avg_lwh_epoch,\n",
    "        \"Average Rot Loss\": avg_rot_epoch\n",
    "    }, step=(epoch+1) * len(trainloader))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
